---
layout: post
title: " [Gi] Các doanh nghiệp có thể làm gì để phát triển AI an toàn, đáng tin ..."
date: Tue, 11 Feb 2025 21:00:00 +0700
categories: entries VN
---
[Các doanh nghiệp có thể làm gì để phát triển AI an toàn, đáng tin ...](https://news.microsoft.com/vi-vn/2025/02/11/cac-doanh-nghiep-co-the-lam-gi-de-phat-trien-he-thong-ai-an-toan-dang-tin-cay/)

![Các doanh nghiệp có thể làm gì để phát triển AI an toàn, đáng tin ...](https://pub-c2c1d9230f0b4abb9b0d2d95e06fd4ef.r2.dev/sites/463/2025/02/responsibily-gradient-1900x1069-1.jpg)

Các doanh nghiệp có thể làm gì để phát triển AI an toàn, đáng tin cậy? Feb 11, 2025 | Microsoft Vietnam Communications.

(For English version, please click HERE)

Trí tuệ nhân tạo tạo sinh (Generative AI) mang đến những thay đổi đáng kể trong nhiều ngành nghề, lĩnh vực. Tuy nhiên, việc phát triển và triển khai các công cụ AI đảm bảo an toàn bảo mật vẫn là một bài toán nan giải đối với nhiều doanh nghiệp. Các lãnh đạo doanh nghiệp đang lo ngại về nhiều rủi ro liên quan tới AI, như tạo ra thông tin sai lệch hoặc có hại, lộ dữ liệu nhạy cảm, bị tấn công mạng hoặc vi phạm luật riêng tư – và đôi khi họ chưa được trang bị đầy đủ để xử lý những rủi ro này.

“Các doanh nghiệp, tổ chức không chỉ quan tâm tới chất lượng và tính hiệu quả của các ứng dụng AI, mà còn cả tính an toàn và bảo mật của những ứng dụng này,” bà Sarah Bird, Giám đốc Sản phẩm mảng AI có trách nhiệm tại Microsoft, cho biết. “Tuy nhiên, nhiều tổ chức vẫn chưa xác định được họ cần làm gì để phát triển một giải pháp AI đáng tin cậy, hoặc họ chưa có những công cụ hỗ trợ cần thiết để làm điều đó.”

Để khắc phục những hạn chế này, Microsoft đã thiết kế các công cụ và dịch vụ hỗ trợ các nhà phát triển trong việc xây dựng và triển khai các hệ thống AI đáng tin cậy, tức là AI được thiết kế với tiêu chí bảo mật, an toàn và quyền riêng tư. Các công cụ và dịch vụ này bao gồm khung nguồn mở PyRIT cho nhóm các chuyên gia kiểm tra và đánh giá các hệ thống AI để xác định những lỗ hổng và rủi ro tiềm ẩn; các đánh giá tự động trong Azure AI Foundry để liên tục đo lường và giám sát rủi ro; và Azure AI Content Safety để phát hiện và chặn các đầu vào và đầu ra độc hại.

Nhờ các công cụ này, nhiều công ty đã ra mắt thành công các công nghệ mới trong các lĩnh vực phức tạp, đòi hỏi sự quản lý chặt chẽ và tuân thủ nghiêm ngặt, chẳng hạn như trợ lý AI tóm tắt hồ sơ bệnh án hay chatbot AI tư vấn thuế cho khách hàng. Cách tiếp cận này cũng giúp các nhà phát triển làm việc hiệu quả hơn.

Bà Mehrnoosh Sameki, Quản lý sản phẩm cấp cao mảng AI có trách nhiệm tại Microsoft cho biết: “Để tạo ra phiên bản đầu tiên của ứng dụng AI tạo sinh rất đơn giản. Tuy nhiên, quá trình triển khai sau đó lại diễn ra chậm hơn trước khi sản phẩm chính thức ra mắt, do doanh nghiệp lo ngại về rủi ro tiềm ẩn do AI, hoặc họ không chắc chắn đã tuân thủ đúng các quy định và yêu cầu chưa. Do đó, các công cụ và dịch vụ hỗ trợ của Microsoft không chỉ giúp triển khai áp dụng AI nhanh chóng hơn mà còn mang lại sự an tâm trong suốt quá trình thử nghiệm và bảo mật ứng dụng.”

Các công cụ này là một phần của phương pháp toàn diện mà Microsoft cung cấp để phát triển AI một cách có trách nhiệm. Phương pháp này là thành quả phối hợp của nhiều đội ngũ tại Microsoft, có thể kể đến nhóm AI Red Team đã xác định các rủi ro tiềm tàng như tình trạng “ảo giác” của AI và hình thức tấn công bằng các lệnh độc hại; các nhà nghiên cứu deepfake và các chuyên gia đo lường đã phát triển hệ thống đánh giá AI; và các kỹ sư đã thiết kế và tinh chỉnh các biện pháp bảo vệ an toàn, v.v.

Theo bà Mehrnoosh Sameki, đối với những công ty chuyên về tư vấn thuế hiện đang tự phát triển chatbot tư vấn cho khách hàng, khả năng giải quyết hiện tượng “ảo giác AI” là vô cùng quan trọng. Việc này đảm bảo thông tin cung cấp cho khách hàng là chính xác. Để tăng cường tính bảo mật, an toàn và riêng tư cho chatbot của mình, các công ty này có thể trang bị các bộ lọc để ngăn chặn các cuộc tấn công bằng lệnh, nội dung độc hại và lộ thông tin nhận dạng cá nhân.

Ngoài ra, một tổ chức chăm sóc y tế đã phát triển một trợ lý tóm tắt bằng AI. Tổ chức này đặc biệt chú trọng vào những công cụ cải thiện độ chính xác cũng như khả năng tạo bộ lọc tùy chỉnh nhằm đảm bảo không có thông tin quan trọng nào bị bỏ sót trong các bản tóm tắt tài liệu.

“Nhiều công cụ của chúng tôi hoạt động như các công cụ gỡ lỗi giúp họ hiểu cách cải thiện ứng dụng của mình,” bà Sameki cho biết. “Cả hai công ty giờ đều có tốc độ triển khai nhanh hơn với mức độ tin cậy cao hơn đáng kể.”

Bên cạnh đó, Microsoft cũng đang hỗ trợ các tổ chức nâng cao khả năng quản trị AI, bao gồm phát triển một hệ thống theo dõi và chia sẻ các thông tin quan trọng về quá trình phát triển, triển khai và vận hành một ứng dụng hoặc mô hình. Hiện được cung cấp dưới dạng bản xem trước riêng tư hiện có trên Azure AI Foundry, các báo cáo AI sẽ giúp các tổ chức cộng tác hiệu quả hơn, đáp ứng các quy định ngày càng chặt chẽ về AI, đồng thời dễ dàng ghi nhận những phân tích về đánh giá, rủi ro tiềm ẩn và các biện pháp giảm thiểu – tất cả trên một nền tảng duy nhất.

Những nỗ lực này là một phần quan trọng trong mục tiêu của Microsoft nhằm giúp mọi cá nhân và tổ chức khai thác tối đa tiềm năng của AI và chia sẻ những kiến thức và kinh nghiệm để mọi người đều có thể làm việc với AI hiệu quả hơn. “Việc xây dựng các hệ thống AI đáng tin cậy là nền tảng trong mọi hoạt động của chúng tôi, và chúng tôi muốn trao quyền cho khách hàng để họ cũng có thể làm được điều đó,” bà Sarah Bird cho biết.

Để tìm hiểu thêm về những bài viết chuyên đề “AI có trách nhiệm” của Microsoft, truy cập tại đây.

